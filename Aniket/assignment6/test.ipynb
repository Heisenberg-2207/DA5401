{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'tokens', 'ner_tags', 'worker_id', 'slot_method', 'judgments'],\n",
      "    num_rows: 11514\n",
      "})\n",
      "{'id': '1', 'locale': 'en-US', 'partition': 'train', 'scenario': 9, 'intent': 55, 'utt': 'wake me up at nine am on friday', 'annot_utt': 'wake me up at [time : nine am] on [date : friday]', 'tokens': ['wake', 'me', 'up', 'at', 'nine', 'am', 'on', 'friday'], 'ner_tags': [0, 0, 0, 0, 60, 16, 0, 7], 'worker_id': '1', 'slot_method': {'slot': [], 'method': []}, 'judgments': {'worker_id': [], 'intent_score': [], 'slots_score': [], 'grammar_score': [], 'spelling_score': [], 'language_identification': []}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"qanastek/MASSIVE\", \"en-US\", split='train')\n",
    "print(dataset)\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   utt  \\\n",
      "0      wake me up at nine am on friday   \n",
      "1  set an alarm for two hours from now   \n",
      "2                           olly quiet   \n",
      "3                                 stop   \n",
      "4           olly pause for ten seconds   \n",
      "\n",
      "                                         tokens language  \n",
      "0      [wake, me, up, at, nine, am, on, friday]    en-US  \n",
      "1  [set, an, alarm, for, two, hours, from, now]    en-US  \n",
      "2                                 [olly, quiet]    en-US  \n",
      "3                                        [stop]    en-US  \n",
      "4              [olly, pause, for, ten, seconds]    en-US  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'utt': dataset['utt'],\n",
    "    'tokens': dataset['tokens'],\n",
    "    'language': dataset['locale']\n",
    "})\n",
    "\n",
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd51cfe5200435ebd3e015d6cf56c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0889f466146d4d31b73d3b4f53e573d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504060408e19497e8c8c00df1f81cb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'tokens', 'ner_tags', 'worker_id', 'slot_method', 'judgments'],\n",
      "    num_rows: 11514\n",
      "})\n",
      "{'id': '1', 'locale': 'af-ZA', 'partition': 'train', 'scenario': 9, 'intent': 55, 'utt': 'maak my wakker nege-uur v. m. op vrydag', 'annot_utt': 'maak my wakker [time : nege-uur v. m.] op [date : vrydag]', 'tokens': ['maak', 'my', 'wakker', 'nege-uur', 'v.', 'm.', 'op', 'vrydag'], 'ner_tags': [0, 0, 0, 60, 16, 16, 0, 7], 'worker_id': '20', 'slot_method': {'slot': ['time', 'date'], 'method': ['translation', 'translation']}, 'judgments': {'worker_id': ['40', '49', '20'], 'intent_score': [1, 1, 1], 'slots_score': [1, 1, 1], 'grammar_score': [4, 4, 4], 'spelling_score': [2, 2, 2], 'language_identification': ['target', 'target', 'target']}}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"qanastek/MASSIVE\", \"af-ZA\", split='train')\n",
    "print(dataset)\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         utt  \\\n",
      "0    maak my wakker nege-uur v. m. op vrydag   \n",
      "1      stel 'n alarm vir twee ure van nou af   \n",
      "2                            janneman stilte   \n",
      "3                                       stop   \n",
      "4  janneman onderbreek dit vir tien sekondes   \n",
      "\n",
      "                                             tokens language  \n",
      "0  [maak, my, wakker, nege-uur, v., m., op, vrydag]    af-ZA  \n",
      "1   [stel, 'n, alarm, vir, twee, ure, van, nou, af]    af-ZA  \n",
      "2                                [janneman, stilte]    af-ZA  \n",
      "3                                            [stop]    af-ZA  \n",
      "4  [janneman, onderbreek, dit, vir, tien, sekondes]    af-ZA  \n"
     ]
    }
   ],
   "source": [
    "df_2 = pd.DataFrame({\n",
    "    'utt': dataset['utt'],\n",
    "    'tokens': dataset['tokens'],\n",
    "    'language': dataset['locale']\n",
    "})\n",
    "\n",
    "print(df_2.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   utt  \\\n",
      "34537    stuur hi in whatsapp na vicky   \n",
      "34538                   het ek e-posse   \n",
      "34539           watter e-posse is nuut   \n",
      "34540  het ek nuwe eposse vanaf pieter   \n",
      "34541          kyk na epos van jeff af   \n",
      "\n",
      "                                       tokens language  \n",
      "34537    [stuur, hi, in, whatsapp, na, vicky]    af-ZA  \n",
      "34538                      [het, ek, e-posse]    af-ZA  \n",
      "34539             [watter, e-posse, is, nuut]    af-ZA  \n",
      "34540  [het, ek, nuwe, eposse, vanaf, pieter]    af-ZA  \n",
      "34541          [kyk, na, epos, van, jeff, af]    af-ZA  \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, df_2], ignore_index=True)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       af-ZA       1.00      1.00      1.00     23028\n",
      "       en-US       0.99      1.00      1.00     11514\n",
      "\n",
      "    accuracy                           1.00     34542\n",
      "   macro avg       1.00      1.00      1.00     34542\n",
      "weighted avg       1.00      1.00      1.00     34542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is already defined and has a 'tokens' column\n",
    "# Convert tokens to strings if necessary\n",
    "df['tokens_str'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['utt'])\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['language'])\n",
    "\n",
    "# Train the Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict and evaluate the classifier\n",
    "y_pred = clf.predict(X)\n",
    "print(classification_report(y, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer results:\n",
      "['bright' 'brown' 'dog' 'fox' 'jump' 'jumps' 'lazy' 'never' 'over' 'quick'\n",
      " 'quickly' 'shines' 'sun' 'the']\n",
      "[[0 1 1 1 0 1 1 0 1 1 0 0 0 2]\n",
      " [0 0 1 0 1 0 1 1 1 0 1 0 0 1]\n",
      " [1 0 1 0 0 0 1 0 1 0 0 1 1 1]]\n",
      "\n",
      "TfidfVectorizer results:\n",
      "['bright' 'brown' 'dog' 'fox' 'jump' 'jumps' 'lazy' 'never' 'over' 'quick'\n",
      " 'quickly' 'shines' 'sun' 'the']\n",
      "[[0.         0.3940004  0.23270298 0.3940004  0.         0.3940004\n",
      "  0.23270298 0.         0.23270298 0.3940004  0.         0.\n",
      "  0.         0.46540596]\n",
      " [0.         0.         0.28171538 0.         0.4769856  0.\n",
      "  0.28171538 0.4769856  0.28171538 0.         0.4769856  0.\n",
      "  0.         0.28171538]\n",
      " [0.4769856  0.         0.28171538 0.         0.         0.\n",
      "  0.28171538 0.         0.28171538 0.         0.         0.4769856\n",
      "  0.4769856  0.28171538]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Never jump over the lazy dog quickly.\",\n",
    "    \"Bright sun shines over the lazy dog.\"\n",
    "]\n",
    "\n",
    "# Using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the matrices to arrays for better readability\n",
    "count_array = count_matrix.toarray()\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Get feature names\n",
    "count_features = count_vectorizer.get_feature_names_out()\n",
    "tfidf_features = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print results\n",
    "print(\"CountVectorizer results:\")\n",
    "print(count_features)\n",
    "print(count_array)\n",
    "\n",
    "print(\"\\nTfidfVectorizer results:\")\n",
    "print(tfidf_features)\n",
    "print(tfidf_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
